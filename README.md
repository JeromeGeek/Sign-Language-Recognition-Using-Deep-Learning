
# Sign Language Recognition Using Deep Learning


Hand gesture recognition is crucial for facilitating communication with individuals who have hearing and vocal disabilities. Sign Language Recognition is a subfield of Hand gesture Recognition that helps in achieving this goal. Our objective is to propose a simple and intuitive model for Sign Language Recognition using deep learning techniques to translate American Sign Language gestures into text. We attained a 96% validation accuracy through the use of techniques such as data collection, pre-processing, segmentation, feature extraction, and classification. Additionally, we compared our CNN model to others.
## Tech Stack

Jupyter Notebook

## Screenshots

![App Screenshot](https://raw.githubusercontent.com/JeromeGeek/Sign-Language-Recognition-Using-Deep-Learning/main/sample_screenshot1.png)
![App Screenshot](https://raw.githubusercontent.com/JeromeGeek/Sign-Language-Recognition-Using-Deep-Learning/main/sample_screenshot2.png)


## Run on Jupyter Notebook

Clone the project

```bash
$  gh repo clone JeromeGeek/Sign-Language-Recognition-Using-Deep-Learning
```

Now open it on Jupyter Notebook and run 

